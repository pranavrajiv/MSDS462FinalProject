{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "    \n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        \n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    \n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    \n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    \n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in labels_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "\n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,'Z':25,'space':26,'del':27,'nothing':28}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function will only work when trying to access from inside AWS notebook\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import json\n",
    "\n",
    "\n",
    "endpoint = '' #get endpoint name from SageMaker > endpoints\n",
    "\n",
    "predictor=sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    serializer=CSVSerializer())\n",
    "\n",
    "while True:\n",
    "    #success, image = cap.read()\n",
    "    image = cv2.imread(\"W_test.jpg\", cv2.IMREAD_COLOR)\n",
    "    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    predictions=\"\"\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
    "            landmark_list = calc_landmark_list(imgRGB, hand_landmarks)\n",
    "            pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "            data = np.array([pre_processed_landmark_list], dtype=np.float32)\n",
    "            predictions = predictor.predict(data)\n",
    "            my_json = predictions.decode(\"utf-8\").replace(\"'\", '\"')\n",
    "            jsonData = json.loads(my_json)\n",
    "            classes_x=np.argmax(np.squeeze(jsonData[\"predictions\"]))\n",
    "            print(\"\\nLabel\")\n",
    "            print(get_key(classes_x))\n",
    "            print(\"\\n\")\n",
    "            cv2.putText(image, get_key(classes_x),(10,60), cv2.FONT_HERSHEY_PLAIN,3, (255,0,255),4)\n",
    "\n",
    "    cv2.imshow(\"Results\", image)\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label\n",
      "W\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Working USING LAMDA FUNCTION\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# grab environment variables\n",
    "ENDPOINT_NAME = ''\n",
    "runtime= boto3.client('runtime.sagemaker', \n",
    "                     region_name='us-east-1', # make sure to set correct region\n",
    "                     aws_access_key_id='',\n",
    "                      aws_secret_access_key='')\n",
    "while True:\n",
    "    #success, image = cap.read()\n",
    "    image = cv2.imread(\"W_test.jpg\", cv2.IMREAD_COLOR)\n",
    "    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    predictions=\"\"\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
    "            landmark_list = calc_landmark_list(imgRGB, hand_landmarks)\n",
    "            pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "            payload = ','.join(str(e) for e in pre_processed_landmark_list)\n",
    "            response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "            \n",
    "            jsonData = json.loads(response['Body'].read().decode())\n",
    "            classes_x=np.argmax(np.squeeze(jsonData[\"predictions\"]))\n",
    "            print(\"\\nLabel\")\n",
    "            print(get_key(classes_x))\n",
    "            print(\"\\n\")\n",
    "            cv2.putText(image, get_key(classes_x),(10,60), cv2.FONT_HERSHEY_PLAIN,3, (255,0,255),4)\n",
    "    #remove the below break statement when you are ready to make mutiple api calls \n",
    "    break\n",
    "    cv2.imshow(\"Results\", image)\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
